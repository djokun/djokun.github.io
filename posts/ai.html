<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="stylesheet" type="text/css" href="/styles/stylesheet.css" media="screen"/>
<link rel="shortcut icon" type="image/x-icon" href="me.ico?">
<title>The Implications of AI</title>
</head>

<html>
<body>
<!-- START SIDENAV -->
  <div class="sidenav">
    <a href="/index.html">Home</a>
    <a href="/posts.html">Posts</a>
    <a href="/books.html">Favorite Books</a>
    <a href="/about.html">About Me</a>
    <a href="/contact.html">Contact</a>
    <a href="/software.html">Computer Stuff</a>
    <a href="/routine.html">Exercise Routine</a>
  </div>
<!-- END SIDENAV -->
  <div class="main">
    <h1>The Implications of AI</h1>
    <p>
      I'm sure I'm not the only person who has noticed that cyberspace (an archaic word, but I like it) is generally split between full-on AI haters and people who can't seem to get enough of it.
      I think of myself as someone who is caught in the crossfire.
      I don't think AI is 100% bad; on the other hand, I do feel a sense of anger when I see obvious AI "slop" content.
      My personal reasons might be different from yours, though, if you feel the same way.
      For me, the anger stems from the feeling that someone is trying to deceive me, similarly to how I would feel if I were told an obvious lie.
      It is not the lie that enrages me, but the attempt.<a href=#f1>[1]</a>
    </p>
    <p id=f1 class=footnote>
      [1] Like you, probably, I've become aware that many LLMs, particularly ChatGPT, often write exactly like this by default, and do so repeatedly: "It is not x, it is y".
      Many people think they can detect if an LLM has written something, but the truth is that most of you can't if it's been prompted well.
      Lazy prompter = lazy LLM.
    </p>
    <p>
      People who were online around 2007 to 2012 probably remember when Adobe Photoshop really took off.
      I might be wrong, and perhaps other people who lived through that period of the Internet could also attest, but I don't remember the culture of "photoshopping" inherently feeling like an act of deception, for multiple reasons.
      The first reason is that photoshopping requires a certain level of human skill to be convincing.
      The second reason is that the scale of photoshop users was tiny and largely limited to people with specific interests such as photography, typography, graphic design, etc.
      In other words, artists.
      We'll come back to that.
    </p>
    <p>
      Finally, that period of Internet culture was very different from the current Internet culture.
      There was not an expectation of truth online.
      The Internet was not considered a real "place".
      The goal of one's social media was not to monetize your "personal brand", therefore innocent acts of deceit were merely shitposts.
    </p>
    <p>
      In contrast, the goal of AI has the feeling, to me at least, of trying to deceive me.
      On an Internet that many have come to accept as being "real", AI users are trying to convince me that their products are human.
      Worse, some are trying to convince me that their products are "real", i.e., real situations with real people and animals.
      Worse still, they have confused actual people over what is real and what is not; those people now often accuse human work and real situations as being the product of an AI.
    </p>
    <p>
      So what do I think is good about AI?
      Well, I occasionally use LLMs for my job when I am writing code.
      Occasionally, because I find that it generally isn't good at creating anything new, which is not surprising if you know how an LLM works.
      That said, sometimes it saves a little bit of time.
      I also don't pay for any LLMs, so perhaps I am limited by their free versions.
      Therefore I would not consider myself a "power user" of LLMs.
      However, for the type of software I write and use, it typically would take me the same amount of time to construct a spec sheet to prompt the LLM with as it would to just write it myself.
      I don't have intrinsic issues with LLM use with coding because I don't believe that code should have a copyright anyway (in the same sense that a cooking recipe does not legally have a copyright).
    </p>
    <p>
      Text-to-image and text-to-video models, collectively referred to as "Generative AI", are different beasts.
      I don't think I'm alone in saying that the potential, and actual, consequences of this technology's rapid improvement is cause for concern.
    </p>
    <footer>
      <i>&#127279; 2025 Daniel J. Okuniewicz Jr. Verbatim copying and distribution of this entire article are permitted worldwide, without royalty, in any medium, provided this notice is preserved.</i>
    </footer>
  </div>
</body>
</html>
